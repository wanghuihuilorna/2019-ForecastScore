{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#import xgboost as xgb\n",
    "#import catboost as cb\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/home/wjunneng/Python/ForecastScore/data/train_s1/exam_score.csv')\n",
    "df_test = pd.read_csv('/home/wjunneng/Python/ForecastScore/data/test_s1/submission_s1.csv')\n",
    "df_test.rename(columns={'pred':'score'},inplace = True)\n",
    "course_class = pd.read_csv('/home/wjunneng/Python/ForecastScore/data/train_s1/course.csv')\n",
    "student = pd.read_csv('/home/wjunneng/Python/ForecastScore/data/train_s1/student.csv')\n",
    "all_know = pd.read_csv('/home/wjunneng/Python/ForecastScore/data/train_s1/all_knowledge.csv')\n",
    "df_all = df_train.append(df_test)\n",
    "df_all = df_all.merge(course_class, on='course', how='left')\n",
    "df_all = df_all.merge(student, on='student_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "tmp1 = df_train.groupby(by=['student_id','course'], as_index=False)['score'].agg({'mean_score':np.mean, 'median_score':np.median, 'std_score':np.std,'max_score':np.max,'min_score':np.min})\n",
    "tmp2 = df_train.groupby(by=['student_id'], as_index=False)['score'].agg({'s_mean_score':np.mean, 's_median_score':np.median, 's_std_score':np.std,'s_max_score':np.max,'min_score':np.min})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df_all=df_all.merge(tmp1, on=['student_id','course'], how='left')\n",
    "df_all=df_all.merge(tmp2, on=['student_id'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/home/wjunneng/Python/anaconda3/envs/lightgbm/lib/python3.6/site-packages/pandas/core/frame.py:7116: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\nof pandas will change to not sort by default.\n\nTo accept the future behavior, pass 'sort=False'.\n\nTo retain the current behavior and silence the warning, pass 'sort=True'.\n\n  sort=sort,\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "course1_exam = pd.read_csv('/home/wjunneng/Python/ForecastScore/data/train_s1/course1_exams.csv')\n",
    "course2_exam = pd.read_csv('/home/wjunneng/Python/ForecastScore/data/train_s1/course2_exams.csv')\n",
    "course3_exam = pd.read_csv('/home/wjunneng/Python/ForecastScore/data/train_s1/course3_exams.csv')\n",
    "course4_exam = pd.read_csv('/home/wjunneng/Python/ForecastScore/data/train_s1/course4_exams.csv')\n",
    "course5_exam = pd.read_csv('/home/wjunneng/Python/ForecastScore/data/train_s1/course5_exams.csv')\n",
    "course6_exam = pd.read_csv('/home/wjunneng/Python/ForecastScore/data/train_s1/course6_exams.csv')\n",
    "course7_exam = pd.read_csv('/home/wjunneng/Python/ForecastScore/data/train_s1/course7_exams.csv')\n",
    "course8_exam = pd.read_csv('/home/wjunneng/Python/ForecastScore/data/train_s1/course8_exams.csv')\n",
    "#col_c1 = [i for i in course1_exam.columns if i not in ['course','exam_id']]\n",
    "tmp4=1\n",
    "for i in [course1_exam,course2_exam,course3_exam,course4_exam,course5_exam,course6_exam,course7_exam,course8_exam]:\n",
    "    name = i\n",
    "    col_c1 = [i for i in name.columns if i not in ['course','exam_id']]\n",
    "    name['course'] ='course'+str(tmp4)\n",
    "    tmp2 =np.array(all_know.loc[all_know['course'] == ('course'+str(tmp4)),:]['complexity'])\n",
    "    tmp = name[col_c1]\n",
    "    tmp3 =np.dot(tmp.values,tmp2)\n",
    "    name['hard'] = tmp3\n",
    "    name['hard_inverse'] = name['hard'].apply(lambda x:1/(x+1e-10))\n",
    "    tmp4 = tmp4+1\n",
    "\n",
    "course_exam = course1_exam.append(course2_exam)\n",
    "course_exam = course_exam.append(course3_exam)\n",
    "course_exam = course_exam.append(course4_exam)\n",
    "course_exam = course_exam.append(course5_exam)\n",
    "course_exam = course_exam.append(course6_exam)\n",
    "course_exam = course_exam.append(course7_exam)\n",
    "course_exam = course_exam.append(course8_exam)\n",
    "course_exam.fillna(0,inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "sub_course_exam = course_exam[['course','exam_id','hard','hard_inverse']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(73500, 16)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 42
    }
   ],
   "source": [
    "df_all.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df_all=df_all.merge(sub_course_exam, on=['exam_id','course'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(73500, 18)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 44
    }
   ],
   "source": [
    "df_all.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "for i in ['course','course_class','exam_id','student_id']:\n",
    "    lbl = LabelEncoder()\n",
    "    #all_data[i+\"_count\"] = all_data.groupby([i])[i].transform('count')\n",
    "    #all_data[i+\"_rank\"] = all_data[i+\"_count\"].rank(method='min')\n",
    "    df_all[i] = lbl.fit_transform(df_all[i].astype(str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df_train = df_all[:65500]\n",
    "df_test = df_all[65500:].reset_index(drop=True)\n",
    "col = [i for i in df_all.columns if i not in ['score']]\n",
    "X_train = df_train[col]\n",
    "y = df_train['score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "   student_id  course  exam_id  course_class  gender  mean_score  \\\n0          80       0      118             0       0   82.611111   \n1          48       0      118             0       0   78.222222   \n2         217       0      118             0       0   80.666667   \n3         329       0      118             0       1   82.555556   \n4         237       0      118             0       0   80.055556   \n\n   median_score  std_score  max_score  min_score_x  s_mean_score  \\\n0          82.5   8.395649         98           67     76.290076   \n1          77.5   4.037407         88           71     86.068702   \n2          80.0   7.483315         96           66     80.511450   \n3          82.0   5.124591         92           76     88.847328   \n4          80.0   4.398826         89           71     82.129771   \n\n   s_median_score  s_std_score  s_max_score  min_score_y  hard  hard_inverse  \n0              77     9.713186           98            0   175      0.005714  \n1              86     7.208105          100           71   175      0.005714  \n2              81     6.476426           96           66   175      0.005714  \n3              90     7.665581          100           68   175      0.005714  \n4              83    12.204915           99            0   175      0.005714  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>course</th>\n      <th>exam_id</th>\n      <th>course_class</th>\n      <th>gender</th>\n      <th>mean_score</th>\n      <th>median_score</th>\n      <th>std_score</th>\n      <th>max_score</th>\n      <th>min_score_x</th>\n      <th>s_mean_score</th>\n      <th>s_median_score</th>\n      <th>s_std_score</th>\n      <th>s_max_score</th>\n      <th>min_score_y</th>\n      <th>hard</th>\n      <th>hard_inverse</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>80</td>\n      <td>0</td>\n      <td>118</td>\n      <td>0</td>\n      <td>0</td>\n      <td>82.611111</td>\n      <td>82.5</td>\n      <td>8.395649</td>\n      <td>98</td>\n      <td>67</td>\n      <td>76.290076</td>\n      <td>77</td>\n      <td>9.713186</td>\n      <td>98</td>\n      <td>0</td>\n      <td>175</td>\n      <td>0.005714</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>48</td>\n      <td>0</td>\n      <td>118</td>\n      <td>0</td>\n      <td>0</td>\n      <td>78.222222</td>\n      <td>77.5</td>\n      <td>4.037407</td>\n      <td>88</td>\n      <td>71</td>\n      <td>86.068702</td>\n      <td>86</td>\n      <td>7.208105</td>\n      <td>100</td>\n      <td>71</td>\n      <td>175</td>\n      <td>0.005714</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>217</td>\n      <td>0</td>\n      <td>118</td>\n      <td>0</td>\n      <td>0</td>\n      <td>80.666667</td>\n      <td>80.0</td>\n      <td>7.483315</td>\n      <td>96</td>\n      <td>66</td>\n      <td>80.511450</td>\n      <td>81</td>\n      <td>6.476426</td>\n      <td>96</td>\n      <td>66</td>\n      <td>175</td>\n      <td>0.005714</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>329</td>\n      <td>0</td>\n      <td>118</td>\n      <td>0</td>\n      <td>1</td>\n      <td>82.555556</td>\n      <td>82.0</td>\n      <td>5.124591</td>\n      <td>92</td>\n      <td>76</td>\n      <td>88.847328</td>\n      <td>90</td>\n      <td>7.665581</td>\n      <td>100</td>\n      <td>68</td>\n      <td>175</td>\n      <td>0.005714</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>237</td>\n      <td>0</td>\n      <td>118</td>\n      <td>0</td>\n      <td>0</td>\n      <td>80.055556</td>\n      <td>80.0</td>\n      <td>4.398826</td>\n      <td>89</td>\n      <td>71</td>\n      <td>82.129771</td>\n      <td>83</td>\n      <td>12.204915</td>\n      <td>99</td>\n      <td>0</td>\n      <td>175</td>\n      <td>0.005714</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 47
    }
   ],
   "source": [
    "X_train.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 20 rounds.\n",
      "[10]\ttrain's rmse: 9.44391\ttrain's l2: 89.1875\tval's rmse: 9.46102\tval's l2: 89.5108\n[20]\ttrain's rmse: 8.94058\ttrain's l2: 79.934\tval's rmse: 8.95885\tval's l2: 80.2611\n[30]\ttrain's rmse: 8.49467\ttrain's l2: 72.1594\tval's rmse: 8.51467\tval's l2: 72.4996\n",
      "[40]\ttrain's rmse: 8.09421\ttrain's l2: 65.5163\tval's rmse: 8.11548\tval's l2: 65.8611\n[50]\ttrain's rmse: 7.75774\ttrain's l2: 60.1825\tval's rmse: 7.7808\tval's l2: 60.5409\n[60]\ttrain's rmse: 7.44475\ttrain's l2: 55.4243\tval's rmse: 7.46978\tval's l2: 55.7976\n",
      "[70]\ttrain's rmse: 7.18888\ttrain's l2: 51.68\tval's rmse: 7.21644\tval's l2: 52.077\n",
      "[80]\ttrain's rmse: 6.9601\ttrain's l2: 48.443\tval's rmse: 6.98994\tval's l2: 48.8593\n[90]\ttrain's rmse: 6.75894\ttrain's l2: 45.6833\tval's rmse: 6.79148\tval's l2: 46.1242\n",
      "[100]\ttrain's rmse: 6.5952\ttrain's l2: 43.4966\tval's rmse: 6.63043\tval's l2: 43.9626\n[110]\ttrain's rmse: 6.45178\ttrain's l2: 41.6255\tval's rmse: 6.49054\tval's l2: 42.1271\n[120]\ttrain's rmse: 6.32602\ttrain's l2: 40.0185\tval's rmse: 6.36718\tval's l2: 40.541\n[130]\ttrain's rmse: 6.22166\ttrain's l2: 38.7091\tval's rmse: 6.26587\tval's l2: 39.2611\n",
      "[140]\ttrain's rmse: 6.13412\ttrain's l2: 37.6274\tval's rmse: 6.18165\tval's l2: 38.2127\n[150]\ttrain's rmse: 6.05777\ttrain's l2: 36.6966\tval's rmse: 6.10809\tval's l2: 37.3088\n[160]\ttrain's rmse: 5.99247\ttrain's l2: 35.9097\tval's rmse: 6.04471\tval's l2: 36.5386\n[170]\ttrain's rmse: 5.93488\ttrain's l2: 35.2228\tval's rmse: 5.99037\tval's l2: 35.8845\n",
      "[180]\ttrain's rmse: 5.88823\ttrain's l2: 34.6712\tval's rmse: 5.94677\tval's l2: 35.364\n[190]\ttrain's rmse: 5.84624\ttrain's l2: 34.1785\tval's rmse: 5.90725\tval's l2: 34.8956\n[200]\ttrain's rmse: 5.81193\ttrain's l2: 33.7785\tval's rmse: 5.87639\tval's l2: 34.532\n[210]\ttrain's rmse: 5.7826\ttrain's l2: 33.4385\tval's rmse: 5.84962\tval's l2: 34.2181\n",
      "[220]\ttrain's rmse: 5.75807\ttrain's l2: 33.1554\tval's rmse: 5.82754\tval's l2: 33.9602\n[230]\ttrain's rmse: 5.73365\ttrain's l2: 32.8747\tval's rmse: 5.80681\tval's l2: 33.719\n[240]\ttrain's rmse: 5.71267\ttrain's l2: 32.6346\tval's rmse: 5.78846\tval's l2: 33.5063\n[250]\ttrain's rmse: 5.69449\ttrain's l2: 32.4273\tval's rmse: 5.77235\tval's l2: 33.3201\n",
      "[260]\ttrain's rmse: 5.68033\ttrain's l2: 32.2661\tval's rmse: 5.76137\tval's l2: 33.1933\n[270]\ttrain's rmse: 5.66473\ttrain's l2: 32.0891\tval's rmse: 5.74896\tval's l2: 33.0506\n[280]\ttrain's rmse: 5.65229\ttrain's l2: 31.9484\tval's rmse: 5.73884\tval's l2: 32.9342\n[290]\ttrain's rmse: 5.64105\ttrain's l2: 31.8214\tval's rmse: 5.73165\tval's l2: 32.8518\n",
      "[300]\ttrain's rmse: 5.63109\ttrain's l2: 31.7092\tval's rmse: 5.72466\tval's l2: 32.7718\n[310]\ttrain's rmse: 5.62199\ttrain's l2: 31.6068\tval's rmse: 5.71892\tval's l2: 32.7061\n[320]\ttrain's rmse: 5.61311\ttrain's l2: 31.507\tval's rmse: 5.71327\tval's l2: 32.6414\n[330]\ttrain's rmse: 5.60382\ttrain's l2: 31.4029\tval's rmse: 5.70768\tval's l2: 32.5776\n",
      "[340]\ttrain's rmse: 5.59583\ttrain's l2: 31.3134\tval's rmse: 5.70165\tval's l2: 32.5089\n[350]\ttrain's rmse: 5.58841\ttrain's l2: 31.2303\tval's rmse: 5.69751\tval's l2: 32.4617\n[360]\ttrain's rmse: 5.58208\ttrain's l2: 31.1597\tval's rmse: 5.69351\tval's l2: 32.4161\n",
      "[370]\ttrain's rmse: 5.57482\ttrain's l2: 31.0786\tval's rmse: 5.68902\tval's l2: 32.365\n[380]\ttrain's rmse: 5.56884\ttrain's l2: 31.0119\tval's rmse: 5.68576\tval's l2: 32.3279\n[390]\ttrain's rmse: 5.56331\ttrain's l2: 30.9504\tval's rmse: 5.68401\tval's l2: 32.3079\n[400]\ttrain's rmse: 5.55664\ttrain's l2: 30.8762\tval's rmse: 5.68016\tval's l2: 32.2642\n[410]\ttrain's rmse: 5.55288\ttrain's l2: 30.8344\tval's rmse: 5.67959\tval's l2: 32.2578\n[420]\ttrain's rmse: 5.54811\ttrain's l2: 30.7816\tval's rmse: 5.67651\tval's l2: 32.2228\n[430]\ttrain's rmse: 5.54416\ttrain's l2: 30.7377\tval's rmse: 5.67547\tval's l2: 32.2109\n[440]\ttrain's rmse: 5.53953\ttrain's l2: 30.6864\tval's rmse: 5.6738\tval's l2: 32.192\n[450]\ttrain's rmse: 5.53471\ttrain's l2: 30.6331\tval's rmse: 5.6714\tval's l2: 32.1648\n[460]\ttrain's rmse: 5.53076\ttrain's l2: 30.5893\tval's rmse: 5.67013\tval's l2: 32.1504\n[470]\ttrain's rmse: 5.52493\ttrain's l2: 30.5248\tval's rmse: 5.66762\tval's l2: 32.1219\n",
      "[480]\ttrain's rmse: 5.52013\ttrain's l2: 30.4718\tval's rmse: 5.66527\tval's l2: 32.0953\n[490]\ttrain's rmse: 5.51427\ttrain's l2: 30.4072\tval's rmse: 5.66164\tval's l2: 32.0542\n[500]\ttrain's rmse: 5.50994\ttrain's l2: 30.3594\tval's rmse: 5.65971\tval's l2: 32.0323\n[510]\ttrain's rmse: 5.50447\ttrain's l2: 30.2992\tval's rmse: 5.65659\tval's l2: 31.997\n[520]\ttrain's rmse: 5.50082\ttrain's l2: 30.259\tval's rmse: 5.65583\tval's l2: 31.9884\n[530]\ttrain's rmse: 5.49624\ttrain's l2: 30.2087\tval's rmse: 5.653\tval's l2: 31.9564\n[540]\ttrain's rmse: 5.49255\ttrain's l2: 30.1681\tval's rmse: 5.65172\tval's l2: 31.942\n[550]\ttrain's rmse: 5.48892\ttrain's l2: 30.1283\tval's rmse: 5.65142\tval's l2: 31.9385\n[560]\ttrain's rmse: 5.48383\ttrain's l2: 30.0724\tval's rmse: 5.64978\tval's l2: 31.92\n[570]\ttrain's rmse: 5.48\ttrain's l2: 30.0304\tval's rmse: 5.64991\tval's l2: 31.9215\n[580]\ttrain's rmse: 5.47762\ttrain's l2: 30.0043\tval's rmse: 5.64985\tval's l2: 31.9209\n[590]\ttrain's rmse: 5.47492\ttrain's l2: 29.9747\tval's rmse: 5.64864\tval's l2: 31.9071\n[600]\ttrain's rmse: 5.47218\ttrain's l2: 29.9448\tval's rmse: 5.64783\tval's l2: 31.8979\n[610]\ttrain's rmse: 5.46895\ttrain's l2: 29.9094\tval's rmse: 5.64742\tval's l2: 31.8933",
      "\n[620]\ttrain's rmse: 5.46541\ttrain's l2: 29.8707\tval's rmse: 5.64695\tval's l2: 31.888\n[630]\ttrain's rmse: 5.46207\ttrain's l2: 29.8342\tval's rmse: 5.64622\tval's l2: 31.8798\n[640]\ttrain's rmse: 5.45935\ttrain's l2: 29.8045\tval's rmse: 5.64663\tval's l2: 31.8844\n[650]\ttrain's rmse: 5.45609\ttrain's l2: 29.7689\tval's rmse: 5.64592\tval's l2: 31.8765\n[660]\ttrain's rmse: 5.45325\ttrain's l2: 29.7379\tval's rmse: 5.64616\tval's l2: 31.8791\n[670]\ttrain's rmse: 5.45065\ttrain's l2: 29.7096\tval's rmse: 5.64592\tval's l2: 31.8764\n[680]\ttrain's rmse: 5.44851\ttrain's l2: 29.6863\tval's rmse: 5.64588\tval's l2: 31.8759\n[690]\ttrain's rmse: 5.44591\ttrain's l2: 29.6579\tval's rmse: 5.64544\tval's l2: 31.871\n[700]\ttrain's rmse: 5.44314\ttrain's l2: 29.6278\tval's rmse: 5.64586\tval's l2: 31.8757\n[710]\ttrain's rmse: 5.44053\ttrain's l2: 29.5993\tval's rmse: 5.64541\tval's l2: 31.8706\n",
      "[720]\ttrain's rmse: 5.4378\ttrain's l2: 29.5697\tval's rmse: 5.64513\tval's l2: 31.8675\n[730]\ttrain's rmse: 5.43522\ttrain's l2: 29.5416\tval's rmse: 5.64613\tval's l2: 31.8788\n[740]\ttrain's rmse: 5.43302\ttrain's l2: 29.5177\tval's rmse: 5.64611\tval's l2: 31.8786\nEarly stopping, best iteration is:\n[723]\ttrain's rmse: 5.43714\ttrain's l2: 29.5624\tval's rmse: 5.64497\tval's l2: 31.8657\n",
      "Training until validation scores don't improve for 20 rounds.\n[10]\ttrain's rmse: 9.44354\ttrain's l2: 89.1805\tval's rmse: 9.44692\tval's l2: 89.2444\n[20]\ttrain's rmse: 8.93988\ttrain's l2: 79.9214\tval's rmse: 8.94479\tval's l2: 80.0093\n[30]\ttrain's rmse: 8.49322\ttrain's l2: 72.1348\tval's rmse: 8.50176\tval's l2: 72.28\n[40]\ttrain's rmse: 8.09026\ttrain's l2: 65.4523\tval's rmse: 8.10213\tval's l2: 65.6445\n[50]\ttrain's rmse: 7.75274\ttrain's l2: 60.1049\tval's rmse: 7.7685\tval's l2: 60.3495\n",
      "[60]\ttrain's rmse: 7.43823\ttrain's l2: 55.3273\tval's rmse: 7.4592\tval's l2: 55.6397\n[70]\ttrain's rmse: 7.1825\ttrain's l2: 51.5883\tval's rmse: 7.20929\tval's l2: 51.9739\n[80]\ttrain's rmse: 6.95346\ttrain's l2: 48.3506\tval's rmse: 6.98671\tval's l2: 48.8141\n[90]\ttrain's rmse: 6.75019\ttrain's l2: 45.5651\tval's rmse: 6.79142\tval's l2: 46.1234\n[100]\ttrain's rmse: 6.58456\ttrain's l2: 43.3564\tval's rmse: 6.63192\tval's l2: 43.9823\n[110]\ttrain's rmse: 6.44109\ttrain's l2: 41.4876\tval's rmse: 6.4951\tval's l2: 42.1863\n[120]\ttrain's rmse: 6.31397\ttrain's l2: 39.8662\tval's rmse: 6.37529\tval's l2: 40.6443\n[130]\ttrain's rmse: 6.20842\ttrain's l2: 38.5445\tval's rmse: 6.2776\tval's l2: 39.4083\n",
      "[140]\ttrain's rmse: 6.12168\ttrain's l2: 37.475\tval's rmse: 6.19683\tval's l2: 38.4007\n[150]\ttrain's rmse: 6.04524\ttrain's l2: 36.5449\tval's rmse: 6.12675\tval's l2: 37.537\n[160]\ttrain's rmse: 5.97933\ttrain's l2: 35.7524\tval's rmse: 6.06702\tval's l2: 36.8088\n[170]\ttrain's rmse: 5.92133\ttrain's l2: 35.0621\tval's rmse: 6.01477\tval's l2: 36.1775\n",
      "[180]\ttrain's rmse: 5.87432\ttrain's l2: 34.5077\tval's rmse: 5.97383\tval's l2: 35.6866\n[190]\ttrain's rmse: 5.83216\ttrain's l2: 34.0141\tval's rmse: 5.93702\tval's l2: 35.2482\n[200]\ttrain's rmse: 5.7977\ttrain's l2: 33.6133\tval's rmse: 5.90861\tval's l2: 34.9116\n[210]\ttrain's rmse: 5.7675\ttrain's l2: 33.264\tval's rmse: 5.88487\tval's l2: 34.6317\n",
      "[220]\ttrain's rmse: 5.74217\ttrain's l2: 32.9725\tval's rmse: 5.86636\tval's l2: 34.4142\n[230]\ttrain's rmse: 5.71832\ttrain's l2: 32.6992\tval's rmse: 5.84818\tval's l2: 34.2012\n[240]\ttrain's rmse: 5.69782\ttrain's l2: 32.4652\tval's rmse: 5.83244\tval's l2: 34.0174\n[250]\ttrain's rmse: 5.67966\ttrain's l2: 32.2585\tval's rmse: 5.81955\tval's l2: 33.8672\n[260]\ttrain's rmse: 5.66412\ttrain's l2: 32.0822\tval's rmse: 5.81004\tval's l2: 33.7565\n[270]\ttrain's rmse: 5.64838\ttrain's l2: 31.9042\tval's rmse: 5.7996\tval's l2: 33.6353\n[280]\ttrain's rmse: 5.63618\ttrain's l2: 31.7665\tval's rmse: 5.79307\tval's l2: 33.5596\n",
      "[290]\ttrain's rmse: 5.62387\ttrain's l2: 31.6279\tval's rmse: 5.7858\tval's l2: 33.4755\n[300]\ttrain's rmse: 5.61364\ttrain's l2: 31.5129\tval's rmse: 5.78026\tval's l2: 33.4114\n[310]\ttrain's rmse: 5.60402\ttrain's l2: 31.405\tval's rmse: 5.77404\tval's l2: 33.3396\n[320]\ttrain's rmse: 5.59445\ttrain's l2: 31.2978\tval's rmse: 5.76817\tval's l2: 33.2718\n[330]\ttrain's rmse: 5.58548\ttrain's l2: 31.1975\tval's rmse: 5.76334\tval's l2: 33.216\n[340]\ttrain's rmse: 5.57874\ttrain's l2: 31.1223\tval's rmse: 5.76038\tval's l2: 33.182\n",
      "[350]\ttrain's rmse: 5.57168\ttrain's l2: 31.0437\tval's rmse: 5.75731\tval's l2: 33.1466\n[360]\ttrain's rmse: 5.56478\ttrain's l2: 30.9667\tval's rmse: 5.75413\tval's l2: 33.11\n[370]\ttrain's rmse: 5.55806\ttrain's l2: 30.8921\tval's rmse: 5.75104\tval's l2: 33.0744\n",
      "[380]\ttrain's rmse: 5.55211\ttrain's l2: 30.826\tval's rmse: 5.74827\tval's l2: 33.0426\n[390]\ttrain's rmse: 5.54679\ttrain's l2: 30.7668\tval's rmse: 5.74668\tval's l2: 33.0244\n[400]\ttrain's rmse: 5.54076\ttrain's l2: 30.7001\tval's rmse: 5.74425\tval's l2: 32.9965\n[410]\ttrain's rmse: 5.53527\ttrain's l2: 30.6392\tval's rmse: 5.74251\tval's l2: 32.9764\n[420]\ttrain's rmse: 5.52932\ttrain's l2: 30.5733\tval's rmse: 5.7387\tval's l2: 32.9327\n[430]\ttrain's rmse: 5.52456\ttrain's l2: 30.5208\tval's rmse: 5.73686\tval's l2: 32.9115\n[440]\ttrain's rmse: 5.51939\ttrain's l2: 30.4636\tval's rmse: 5.73548\tval's l2: 32.8957\n[450]\ttrain's rmse: 5.51437\ttrain's l2: 30.4083\tval's rmse: 5.73382\tval's l2: 32.8767\n[460]\ttrain's rmse: 5.50967\ttrain's l2: 30.3564\tval's rmse: 5.732\tval's l2: 32.8558\n[470]\ttrain's rmse: 5.50374\ttrain's l2: 30.2912\tval's rmse: 5.73047\tval's l2: 32.8383\n",
      "[480]\ttrain's rmse: 5.49969\ttrain's l2: 30.2465\tval's rmse: 5.7296\tval's l2: 32.8284\n[490]\ttrain's rmse: 5.49407\ttrain's l2: 30.1848\tval's rmse: 5.72775\tval's l2: 32.8071\n[500]\ttrain's rmse: 5.49026\ttrain's l2: 30.143\tval's rmse: 5.72673\tval's l2: 32.7954\n[510]\ttrain's rmse: 5.48402\ttrain's l2: 30.0745\tval's rmse: 5.72457\tval's l2: 32.7707\n",
      "[520]\ttrain's rmse: 5.47989\ttrain's l2: 30.0292\tval's rmse: 5.72439\tval's l2: 32.7687\n[530]\ttrain's rmse: 5.47444\ttrain's l2: 29.9695\tval's rmse: 5.72246\tval's l2: 32.7466\n[540]\ttrain's rmse: 5.47006\ttrain's l2: 29.9216\tval's rmse: 5.72198\tval's l2: 32.741\n[550]\ttrain's rmse: 5.46731\ttrain's l2: 29.8914\tval's rmse: 5.72174\tval's l2: 32.7383\n[560]\ttrain's rmse: 5.46298\ttrain's l2: 29.8442\tval's rmse: 5.72163\tval's l2: 32.737\n[570]\ttrain's rmse: 5.45977\ttrain's l2: 29.8091\tval's rmse: 5.72254\tval's l2: 32.7475\nEarly stopping, best iteration is:\n[556]\ttrain's rmse: 5.46423\ttrain's l2: 29.8578\tval's rmse: 5.72113\tval's l2: 32.7314\n",
      "Training until validation scores don't improve for 20 rounds.\n[10]\ttrain's rmse: 9.44631\ttrain's l2: 89.2328\tval's rmse: 9.44954\tval's l2: 89.2938\n[20]\ttrain's rmse: 8.94429\ttrain's l2: 80.0003\tval's rmse: 8.94776\tval's l2: 80.0625\n",
      "[30]\ttrain's rmse: 8.50005\ttrain's l2: 72.2508\tval's rmse: 8.50398\tval's l2: 72.3176\n[40]\ttrain's rmse: 8.09691\ttrain's l2: 65.56\tval's rmse: 8.10133\tval's l2: 65.6316\n[50]\ttrain's rmse: 7.76223\ttrain's l2: 60.2521\tval's rmse: 7.76737\tval's l2: 60.332\n[60]\ttrain's rmse: 7.4501\ttrain's l2: 55.504\tval's rmse: 7.4555\tval's l2: 55.5845\n[70]\ttrain's rmse: 7.19503\ttrain's l2: 51.7685\tval's rmse: 7.20118\tval's l2: 51.8569\n[80]\ttrain's rmse: 6.96824\ttrain's l2: 48.5564\tval's rmse: 6.97519\tval's l2: 48.6533\n[90]\ttrain's rmse: 6.76789\ttrain's l2: 45.8043\tval's rmse: 6.77561\tval's l2: 45.9089\n[100]\ttrain's rmse: 6.60359\ttrain's l2: 43.6074\tval's rmse: 6.61246\tval's l2: 43.7246\n[110]\ttrain's rmse: 6.46019\ttrain's l2: 41.7341\tval's rmse: 6.47115\tval's l2: 41.8758\n[120]\ttrain's rmse: 6.33297\ttrain's l2: 40.1066\tval's rmse: 6.34493\tval's l2: 40.2582\n[130]\ttrain's rmse: 6.22805\ttrain's l2: 38.7886\tval's rmse: 6.24241\tval's l2: 38.9677\n[140]\ttrain's rmse: 6.14125\ttrain's l2: 37.715\tval's rmse: 6.15766\tval's l2: 37.9168\n[150]\ttrain's rmse: 6.06495\ttrain's l2: 36.7837\tval's rmse: 6.08403\tval's l2: 37.0154\n[160]\ttrain's rmse: 5.99937\ttrain's l2: 35.9925\tval's rmse: 6.02179\tval's l2: 36.2619\n",
      "[170]\ttrain's rmse: 5.94192\ttrain's l2: 35.3064\tval's rmse: 5.96572\tval's l2: 35.5898\n[180]\ttrain's rmse: 5.89612\ttrain's l2: 34.7643\tval's rmse: 5.92223\tval's l2: 35.0728\n[190]\ttrain's rmse: 5.85415\ttrain's l2: 34.2711\tval's rmse: 5.88152\tval's l2: 34.5923\n[200]\ttrain's rmse: 5.82022\ttrain's l2: 33.875\tval's rmse: 5.8507\tval's l2: 34.2307\n[210]\ttrain's rmse: 5.79045\ttrain's l2: 33.5293\tval's rmse: 5.82426\tval's l2: 33.922\n[220]\ttrain's rmse: 5.76504\ttrain's l2: 33.2357\tval's rmse: 5.80129\tval's l2: 33.655\n[230]\ttrain's rmse: 5.74086\ttrain's l2: 32.9575\tval's rmse: 5.77984\tval's l2: 33.4065\n[240]\ttrain's rmse: 5.71995\ttrain's l2: 32.7178\tval's rmse: 5.76223\tval's l2: 33.2033\n[250]\ttrain's rmse: 5.70155\ttrain's l2: 32.5077\tval's rmse: 5.74713\tval's l2: 33.0295\n[260]\ttrain's rmse: 5.68595\ttrain's l2: 32.33\tval's rmse: 5.73599\tval's l2: 32.9016\n[270]\ttrain's rmse: 5.67022\ttrain's l2: 32.1514\tval's rmse: 5.72369\tval's l2: 32.7607\n[280]\ttrain's rmse: 5.65711\ttrain's l2: 32.0029\tval's rmse: 5.71423\tval's l2: 32.6525\n",
      "[290]\ttrain's rmse: 5.64503\ttrain's l2: 31.8663\tval's rmse: 5.70507\tval's l2: 32.5478\n[300]\ttrain's rmse: 5.63514\ttrain's l2: 31.7549\tval's rmse: 5.69854\tval's l2: 32.4734\n[310]\ttrain's rmse: 5.62561\ttrain's l2: 31.6474\tval's rmse: 5.6908\tval's l2: 32.3852\n[320]\ttrain's rmse: 5.61649\ttrain's l2: 31.5449\tval's rmse: 5.68397\tval's l2: 32.3076\n[330]\ttrain's rmse: 5.60708\ttrain's l2: 31.4393\tval's rmse: 5.67891\tval's l2: 32.25\n[340]\ttrain's rmse: 5.59852\ttrain's l2: 31.3434\tval's rmse: 5.6735\tval's l2: 32.1886\n[350]\ttrain's rmse: 5.59148\ttrain's l2: 31.2646\tval's rmse: 5.66849\tval's l2: 32.1318\n[360]\ttrain's rmse: 5.58536\ttrain's l2: 31.1962\tval's rmse: 5.66504\tval's l2: 32.0926\n[370]\ttrain's rmse: 5.57841\ttrain's l2: 31.1187\tval's rmse: 5.66132\tval's l2: 32.0505\n[380]\ttrain's rmse: 5.57237\ttrain's l2: 31.0513\tval's rmse: 5.65917\tval's l2: 32.0262\n",
      "[390]\ttrain's rmse: 5.56753\ttrain's l2: 30.9974\tval's rmse: 5.65798\tval's l2: 32.0127\n[400]\ttrain's rmse: 5.56194\ttrain's l2: 30.9352\tval's rmse: 5.65488\tval's l2: 31.9776\n[410]\ttrain's rmse: 5.55838\ttrain's l2: 30.8955\tval's rmse: 5.6535\tval's l2: 31.962\n[420]\ttrain's rmse: 5.55293\ttrain's l2: 30.835\tval's rmse: 5.65163\tval's l2: 31.9409\n[430]\ttrain's rmse: 5.54809\ttrain's l2: 30.7813\tval's rmse: 5.65029\tval's l2: 31.9258\n[440]\ttrain's rmse: 5.54219\ttrain's l2: 30.7159\tval's rmse: 5.64819\tval's l2: 31.9021\n[450]\ttrain's rmse: 5.53691\ttrain's l2: 30.6574\tval's rmse: 5.64659\tval's l2: 31.884\n[460]\ttrain's rmse: 5.53139\ttrain's l2: 30.5963\tval's rmse: 5.64493\tval's l2: 31.8652\n[470]\ttrain's rmse: 5.52584\ttrain's l2: 30.5349\tval's rmse: 5.64196\tval's l2: 31.8318\n[480]\ttrain's rmse: 5.52199\ttrain's l2: 30.4923\tval's rmse: 5.6406\tval's l2: 31.8163\n[490]\ttrain's rmse: 5.51666\ttrain's l2: 30.4335\tval's rmse: 5.63859\tval's l2: 31.7937\n[500]\ttrain's rmse: 5.51267\ttrain's l2: 30.3896\tval's rmse: 5.63877\tval's l2: 31.7957\n",
      "[510]\ttrain's rmse: 5.50725\ttrain's l2: 30.3299\tval's rmse: 5.6361\tval's l2: 31.7656\n[520]\ttrain's rmse: 5.50196\ttrain's l2: 30.2716\tval's rmse: 5.63524\tval's l2: 31.7559\n[530]\ttrain's rmse: 5.49733\ttrain's l2: 30.2206\tval's rmse: 5.63342\tval's l2: 31.7354\n[540]\ttrain's rmse: 5.493\ttrain's l2: 30.1731\tval's rmse: 5.63236\tval's l2: 31.7235\n[550]\ttrain's rmse: 5.48949\ttrain's l2: 30.1345\tval's rmse: 5.63336\tval's l2: 31.7348\n[560]\ttrain's rmse: 5.48575\ttrain's l2: 30.0934\tval's rmse: 5.63333\tval's l2: 31.7344\nEarly stopping, best iteration is:\n[540]\ttrain's rmse: 5.493\ttrain's l2: 30.1731\tval's rmse: 5.63236\tval's l2: 31.7235\n",
      "Training until validation scores don't improve for 20 rounds.\n[10]\ttrain's rmse: 9.44911\ttrain's l2: 89.2857\tval's rmse: 9.44429\tval's l2: 89.1947\n[20]\ttrain's rmse: 8.9475\ttrain's l2: 80.0577\tval's rmse: 8.94545\tval's l2: 80.021\n[30]\ttrain's rmse: 8.50181\ttrain's l2: 72.2807\tval's rmse: 8.50149\tval's l2: 72.2754\n[40]\ttrain's rmse: 8.09769\ttrain's l2: 65.5725\tval's rmse: 8.09996\tval's l2: 65.6094\n",
      "[50]\ttrain's rmse: 7.76114\ttrain's l2: 60.2353\tval's rmse: 7.76586\tval's l2: 60.3086\n[60]\ttrain's rmse: 7.44727\ttrain's l2: 55.4619\tval's rmse: 7.45505\tval's l2: 55.5777\n[70]\ttrain's rmse: 7.19067\ttrain's l2: 51.7057\tval's rmse: 7.20155\tval's l2: 51.8623\n[80]\ttrain's rmse: 6.96288\ttrain's l2: 48.4817\tval's rmse: 6.97641\tval's l2: 48.6703\n[90]\ttrain's rmse: 6.76135\ttrain's l2: 45.7159\tval's rmse: 6.77805\tval's l2: 45.942\n[100]\ttrain's rmse: 6.59722\ttrain's l2: 43.5233\tval's rmse: 6.61645\tval's l2: 43.7774\n[110]\ttrain's rmse: 6.45384\ttrain's l2: 41.652\tval's rmse: 6.47724\tval's l2: 41.9546\n[120]\ttrain's rmse: 6.32761\ttrain's l2: 40.0386\tval's rmse: 6.35364\tval's l2: 40.3687\n[130]\ttrain's rmse: 6.22326\ttrain's l2: 38.7289\tval's rmse: 6.25326\tval's l2: 39.1032\n[140]\ttrain's rmse: 6.13604\ttrain's l2: 37.651\tval's rmse: 6.16873\tval's l2: 38.0532\n",
      "[150]\ttrain's rmse: 6.05989\ttrain's l2: 36.7223\tval's rmse: 6.09562\tval's l2: 37.1565\n[160]\ttrain's rmse: 5.99494\ttrain's l2: 35.9393\tval's rmse: 6.03406\tval's l2: 36.4099\n[170]\ttrain's rmse: 5.93735\ttrain's l2: 35.2521\tval's rmse: 5.97901\tval's l2: 35.7486\n[180]\ttrain's rmse: 5.89067\ttrain's l2: 34.7\tval's rmse: 5.93553\tval's l2: 35.2305\n[190]\ttrain's rmse: 5.84878\ttrain's l2: 34.2082\tval's rmse: 5.8972\tval's l2: 34.7769\n[200]\ttrain's rmse: 5.81483\ttrain's l2: 33.8123\tval's rmse: 5.86678\tval's l2: 34.4191\n[210]\ttrain's rmse: 5.78485\ttrain's l2: 33.4645\tval's rmse: 5.84116\tval's l2: 34.1192\n[220]\ttrain's rmse: 5.76016\ttrain's l2: 33.1794\tval's rmse: 5.81968\tval's l2: 33.8687\n[230]\ttrain's rmse: 5.73625\ttrain's l2: 32.9046\tval's rmse: 5.79876\tval's l2: 33.6256\n",
      "[240]\ttrain's rmse: 5.71508\ttrain's l2: 32.6622\tval's rmse: 5.78101\tval's l2: 33.4201\n[250]\ttrain's rmse: 5.69589\ttrain's l2: 32.4432\tval's rmse: 5.76521\tval's l2: 33.2376\n[260]\ttrain's rmse: 5.68104\ttrain's l2: 32.2742\tval's rmse: 5.75303\tval's l2: 33.0974\n[270]\ttrain's rmse: 5.66579\ttrain's l2: 32.1012\tval's rmse: 5.74143\tval's l2: 32.964\n[280]\ttrain's rmse: 5.65407\ttrain's l2: 31.9685\tval's rmse: 5.73349\tval's l2: 32.8729\n[290]\ttrain's rmse: 5.64266\ttrain's l2: 31.8396\tval's rmse: 5.72626\tval's l2: 32.79\n[300]\ttrain's rmse: 5.63246\ttrain's l2: 31.7246\tval's rmse: 5.71967\tval's l2: 32.7147\n[310]\ttrain's rmse: 5.62235\ttrain's l2: 31.6108\tval's rmse: 5.71359\tval's l2: 32.6452\n[320]\ttrain's rmse: 5.61229\ttrain's l2: 31.4978\tval's rmse: 5.70726\tval's l2: 32.5728\n[330]\ttrain's rmse: 5.60334\ttrain's l2: 31.3974\tval's rmse: 5.70192\tval's l2: 32.5119\n[340]\ttrain's rmse: 5.59502\ttrain's l2: 31.3043\tval's rmse: 5.69732\tval's l2: 32.4595\n[350]\ttrain's rmse: 5.58729\ttrain's l2: 31.2179\tval's rmse: 5.69261\tval's l2: 32.4058\n[360]\ttrain's rmse: 5.58074\ttrain's l2: 31.1447\tval's rmse: 5.68842\tval's l2: 32.3581\n",
      "[370]\ttrain's rmse: 5.57419\ttrain's l2: 31.0716\tval's rmse: 5.68546\tval's l2: 32.3245\n[380]\ttrain's rmse: 5.56822\ttrain's l2: 31.005\tval's rmse: 5.68295\tval's l2: 32.2959\n[390]\ttrain's rmse: 5.56292\ttrain's l2: 30.9461\tval's rmse: 5.68109\tval's l2: 32.2748\n[400]\ttrain's rmse: 5.5562\ttrain's l2: 30.8714\tval's rmse: 5.67733\tval's l2: 32.232\n[410]\ttrain's rmse: 5.55158\ttrain's l2: 30.82\tval's rmse: 5.67528\tval's l2: 32.2088\n[420]\ttrain's rmse: 5.5457\ttrain's l2: 30.7548\tval's rmse: 5.67249\tval's l2: 32.1771\n[430]\ttrain's rmse: 5.54126\ttrain's l2: 30.7055\tval's rmse: 5.67071\tval's l2: 32.157\n[440]\ttrain's rmse: 5.53613\ttrain's l2: 30.6487\tval's rmse: 5.6683\tval's l2: 32.1296\n[450]\ttrain's rmse: 5.53136\ttrain's l2: 30.596\tval's rmse: 5.66655\tval's l2: 32.1098\n[460]\ttrain's rmse: 5.52694\ttrain's l2: 30.547\tval's rmse: 5.66596\tval's l2: 32.1031\n[470]\ttrain's rmse: 5.52211\ttrain's l2: 30.4937\tval's rmse: 5.66376\tval's l2: 32.0782\n[480]\ttrain's rmse: 5.51714\ttrain's l2: 30.4388\tval's rmse: 5.66382\tval's l2: 32.0788\n[490]\ttrain's rmse: 5.51126\ttrain's l2: 30.374\tval's rmse: 5.66112\tval's l2: 32.0483\n[500]\ttrain's rmse: 5.50768\ttrain's l2: 30.3346\tval's rmse: 5.65997\tval's l2: 32.0352\n",
      "[510]\ttrain's rmse: 5.50305\ttrain's l2: 30.2836\tval's rmse: 5.65824\tval's l2: 32.0157\n[520]\ttrain's rmse: 5.49879\ttrain's l2: 30.2367\tval's rmse: 5.65692\tval's l2: 32.0008\n[530]\ttrain's rmse: 5.49396\ttrain's l2: 30.1836\tval's rmse: 5.65412\tval's l2: 31.9691\n[540]\ttrain's rmse: 5.48971\ttrain's l2: 30.137\tval's rmse: 5.65288\tval's l2: 31.9551\n[550]\ttrain's rmse: 5.48638\ttrain's l2: 30.1004\tval's rmse: 5.65197\tval's l2: 31.9447\n[560]\ttrain's rmse: 5.48225\ttrain's l2: 30.0551\tval's rmse: 5.65052\tval's l2: 31.9283\n[570]\ttrain's rmse: 5.47972\ttrain's l2: 30.0274\tval's rmse: 5.65015\tval's l2: 31.9242\n[580]\ttrain's rmse: 5.47678\ttrain's l2: 29.9951\tval's rmse: 5.64868\tval's l2: 31.9076\n[590]\ttrain's rmse: 5.47412\ttrain's l2: 29.966\tval's rmse: 5.64796\tval's l2: 31.8995\n[600]\ttrain's rmse: 5.47068\ttrain's l2: 29.9284\tval's rmse: 5.6474\tval's l2: 31.8931\n[610]\ttrain's rmse: 5.46764\ttrain's l2: 29.895\tval's rmse: 5.64691\tval's l2: 31.8876\n[620]\ttrain's rmse: 5.46387\ttrain's l2: 29.8539\tval's rmse: 5.64532\tval's l2: 31.8697\n[630]\ttrain's rmse: 5.46031\ttrain's l2: 29.815\tval's rmse: 5.64299\tval's l2: 31.8434\n[640]\ttrain's rmse: 5.45825\ttrain's l2: 29.7924\tval's rmse: 5.64415\tval's l2: 31.8565\n[650]\ttrain's rmse: 5.45526\ttrain's l2: 29.7598\tval's rmse: 5.64335\tval's l2: 31.8474\nEarly stopping, best iteration is:\n[630]\ttrain's rmse: 5.46031\ttrain's l2: 29.815\tval's rmse: 5.64299\tval's l2: 31.8434\n",
      "Training until validation scores don't improve for 20 rounds.\n[10]\ttrain's rmse: 9.44854\ttrain's l2: 89.2749\tval's rmse: 9.44248\tval's l2: 89.1605\n[20]\ttrain's rmse: 8.945\ttrain's l2: 80.0129\tval's rmse: 8.94833\tval's l2: 80.0725\n[30]\ttrain's rmse: 8.49959\ttrain's l2: 72.2431\tval's rmse: 8.51057\tval's l2: 72.4299\n[40]\ttrain's rmse: 8.09571\ttrain's l2: 65.5406\tval's rmse: 8.11462\tval's l2: 65.847\n[50]\ttrain's rmse: 7.75814\ttrain's l2: 60.1888\tval's rmse: 7.78384\tval's l2: 60.5881\n[60]\ttrain's rmse: 7.44386\ttrain's l2: 55.411\tval's rmse: 7.47509\tval's l2: 55.877\n[70]\ttrain's rmse: 7.18766\ttrain's l2: 51.6625\tval's rmse: 7.22436\tval's l2: 52.1914\n",
      "[80]\ttrain's rmse: 6.95849\ttrain's l2: 48.4205\tval's rmse: 6.9999\tval's l2: 48.9986\n[90]\ttrain's rmse: 6.75651\ttrain's l2: 45.6504\tval's rmse: 6.80241\tval's l2: 46.2727\n[100]\ttrain's rmse: 6.59135\ttrain's l2: 43.4459\tval's rmse: 6.64147\tval's l2: 44.1091\n[110]\ttrain's rmse: 6.44831\ttrain's l2: 41.5806\tval's rmse: 6.5032\tval's l2: 42.2917\n[120]\ttrain's rmse: 6.32128\ttrain's l2: 39.9586\tval's rmse: 6.38045\tval's l2: 40.7101\n[130]\ttrain's rmse: 6.21587\ttrain's l2: 38.637\tval's rmse: 6.27981\tval's l2: 39.436\n[140]\ttrain's rmse: 6.12802\ttrain's l2: 37.5526\tval's rmse: 6.19652\tval's l2: 38.3968\n",
      "[150]\ttrain's rmse: 6.05132\ttrain's l2: 36.6185\tval's rmse: 6.12443\tval's l2: 37.5086\n[160]\ttrain's rmse: 5.98499\ttrain's l2: 35.8202\tval's rmse: 6.06202\tval's l2: 36.7481\n[170]\ttrain's rmse: 5.92707\ttrain's l2: 35.1302\tval's rmse: 6.00842\tval's l2: 36.1011\n[180]\ttrain's rmse: 5.8801\ttrain's l2: 34.5756\tval's rmse: 5.96595\tval's l2: 35.5926\n[190]\ttrain's rmse: 5.83768\ttrain's l2: 34.0785\tval's rmse: 5.92777\tval's l2: 35.1384\n[200]\ttrain's rmse: 5.80338\ttrain's l2: 33.6792\tval's rmse: 5.89729\tval's l2: 34.778\n[210]\ttrain's rmse: 5.77354\ttrain's l2: 33.3337\tval's rmse: 5.87116\tval's l2: 34.4705",
      "\n[220]\ttrain's rmse: 5.74774\ttrain's l2: 33.0366\tval's rmse: 5.84948\tval's l2: 34.2164\n[230]\ttrain's rmse: 5.72342\ttrain's l2: 32.7575\tval's rmse: 5.82904\tval's l2: 33.9777\n[240]\ttrain's rmse: 5.70236\ttrain's l2: 32.517\tval's rmse: 5.81138\tval's l2: 33.7722\n[250]\ttrain's rmse: 5.68428\ttrain's l2: 32.311\tval's rmse: 5.79719\tval's l2: 33.6074\n[260]\ttrain's rmse: 5.66947\ttrain's l2: 32.1429\tval's rmse: 5.78546\tval's l2: 33.4716\n[270]\ttrain's rmse: 5.65372\ttrain's l2: 31.9645\tval's rmse: 5.77423\tval's l2: 33.3417\n[280]\ttrain's rmse: 5.64138\ttrain's l2: 31.8251\tval's rmse: 5.7647\tval's l2: 33.2317\n[290]\ttrain's rmse: 5.62981\ttrain's l2: 31.6948\tval's rmse: 5.75627\tval's l2: 33.1347\n[300]\ttrain's rmse: 5.61929\ttrain's l2: 31.5764\tval's rmse: 5.74934\tval's l2: 33.0549\n[310]\ttrain's rmse: 5.60912\ttrain's l2: 31.4622\tval's rmse: 5.74308\tval's l2: 32.9829\n[320]\ttrain's rmse: 5.5989\ttrain's l2: 31.3477\tval's rmse: 5.73678\tval's l2: 32.9107\n",
      "[330]\ttrain's rmse: 5.59064\ttrain's l2: 31.2553\tval's rmse: 5.73184\tval's l2: 32.854\n[340]\ttrain's rmse: 5.5828\ttrain's l2: 31.1677\tval's rmse: 5.7266\tval's l2: 32.7939\n[350]\ttrain's rmse: 5.57561\ttrain's l2: 31.0874\tval's rmse: 5.72337\tval's l2: 32.757\n[360]\ttrain's rmse: 5.56915\ttrain's l2: 31.0154\tval's rmse: 5.71993\tval's l2: 32.7176\n[370]\ttrain's rmse: 5.56234\ttrain's l2: 30.9396\tval's rmse: 5.71578\tval's l2: 32.6701\n[380]\ttrain's rmse: 5.55599\ttrain's l2: 30.869\tval's rmse: 5.71273\tval's l2: 32.6353\n[390]\ttrain's rmse: 5.55075\ttrain's l2: 30.8108\tval's rmse: 5.71053\tval's l2: 32.6101\n[400]\ttrain's rmse: 5.54365\ttrain's l2: 30.7321\tval's rmse: 5.70692\tval's l2: 32.5689\n[410]\ttrain's rmse: 5.53978\ttrain's l2: 30.6892\tval's rmse: 5.70634\tval's l2: 32.5623\n[420]\ttrain's rmse: 5.53492\ttrain's l2: 30.6353\tval's rmse: 5.70414\tval's l2: 32.5372\n[430]\ttrain's rmse: 5.53002\ttrain's l2: 30.5812\tval's rmse: 5.70312\tval's l2: 32.5255\n[440]\ttrain's rmse: 5.52463\ttrain's l2: 30.5216\tval's rmse: 5.70005\tval's l2: 32.4906\n[450]\ttrain's rmse: 5.52001\ttrain's l2: 30.4705\tval's rmse: 5.69814\tval's l2: 32.4688\n[460]\ttrain's rmse: 5.51499\ttrain's l2: 30.4152\tval's rmse: 5.69631\tval's l2: 32.4479\n",
      "[470]\ttrain's rmse: 5.50937\ttrain's l2: 30.3532\tval's rmse: 5.69447\tval's l2: 32.427\n[480]\ttrain's rmse: 5.50424\ttrain's l2: 30.2966\tval's rmse: 5.69353\tval's l2: 32.4162\n[490]\ttrain's rmse: 5.49853\ttrain's l2: 30.2339\tval's rmse: 5.69136\tval's l2: 32.3915\n[500]\ttrain's rmse: 5.49425\ttrain's l2: 30.1867\tval's rmse: 5.69028\tval's l2: 32.3793\n[510]\ttrain's rmse: 5.48858\ttrain's l2: 30.1245\tval's rmse: 5.68805\tval's l2: 32.354\n[520]\ttrain's rmse: 5.48446\ttrain's l2: 30.0793\tval's rmse: 5.68744\tval's l2: 32.347\n[530]\ttrain's rmse: 5.48043\ttrain's l2: 30.0351\tval's rmse: 5.68643\tval's l2: 32.3355\n[540]\ttrain's rmse: 5.4767\ttrain's l2: 29.9942\tval's rmse: 5.68632\tval's l2: 32.3342\nEarly stopping, best iteration is:\n[529]\ttrain's rmse: 5.48053\ttrain's l2: 30.0362\tval's rmse: 5.68602\tval's l2: 32.3308\n",
      "CV score:  5.665494296362461\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "/home/wjunneng/Python/anaconda3/envs/lightgbm/lib/python3.6/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n  % (min_groups, self.n_splits)), Warning)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "test_y = np.zeros(len(df_test))\n",
    "random_seed = 2018\n",
    "cv_model = []\n",
    "cv_score = []\n",
    "skf = StratifiedKFold(n_splits=5, random_state=random_seed, shuffle=True)\n",
    "for index, (train_index, test_index) in enumerate(skf.split(X_train, y)):\n",
    "    #print(index)\n",
    "    train_x, val_x, train_y, val_y = X_train.iloc[train_index], X_train.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "    lgb_params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'n_estimators': 10000,\n",
    "        #'metric': 'mae',\n",
    "        'learning_rate': 0.01,\n",
    "        'min_child_samples': 46,\n",
    "        'min_child_weight': 0.01,\n",
    "        'subsample_freq': 1,\n",
    "        'num_leaves': 40,\n",
    "        'max_depth': 7,\n",
    "        'subsample': 0.42,\n",
    "        'colsample_bytree': 0.48,\n",
    "        'reg_alpha': 0.15,\n",
    "        'reg_lambda': 5,\n",
    "        'verbose': -1,\n",
    "        'seed': 4590\n",
    "    }\n",
    "    lgb = LGBMRegressor(**lgb_params)\n",
    "\n",
    "\n",
    "    lgb.fit(\n",
    "        train_x,\n",
    "        train_y,\n",
    "        eval_set=[(train_x, train_y), (val_x, val_y)],\n",
    "        eval_names=['train', 'val'],\n",
    "        eval_metric='rmse',\n",
    "        #eval_metric = evaluate_macroF1_lgb, \n",
    "        early_stopping_rounds=20,\n",
    "        verbose=10,\n",
    "    )\n",
    "    cv_model.append(lgb)\n",
    "    lgb.n_estimators = lgb.best_iteration_\n",
    "    val_y_pred = lgb.predict(val_x)\n",
    "    cv_score.append( np.sqrt(mean_squared_error(val_y,val_y_pred)))\n",
    "    test_y += lgb.predict(df_test[col])/5\n",
    "print(\"CV score: \",np.mean(cv_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([81.61697357, 77.79347135, 79.81865341, ..., 75.74669072,\n       71.2816731 , 70.32504392])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 49
    }
   ],
   "source": [
    "test_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "sub_test = pd.read_csv('/home/wjunneng/Python/ForecastScore/data/test_s1/submission_s1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "sub_test['pred'] = test_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      student_id   course   exam_id       pred\n0         230748  course1  m31I6cTD  81.616974\n1         186851  course1  m31I6cTD  77.793471\n2         478370  course1  m31I6cTD  79.818653\n3         692328  course1  m31I6cTD  82.282675\n4         509128  course1  m31I6cTD  79.493475\n...          ...      ...       ...        ...\n7995      743747  course8  Vdo50vyP  86.245411\n7996      719678  course8  Vdo50vyP  82.493726\n7997      227750  course8  Vdo50vyP  75.746691\n7998      181683  course8  Vdo50vyP  71.281673\n7999      270481  course8  Vdo50vyP  70.325044\n\n[8000 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>course</th>\n      <th>exam_id</th>\n      <th>pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>230748</td>\n      <td>course1</td>\n      <td>m31I6cTD</td>\n      <td>81.616974</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>186851</td>\n      <td>course1</td>\n      <td>m31I6cTD</td>\n      <td>77.793471</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>478370</td>\n      <td>course1</td>\n      <td>m31I6cTD</td>\n      <td>79.818653</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>692328</td>\n      <td>course1</td>\n      <td>m31I6cTD</td>\n      <td>82.282675</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>509128</td>\n      <td>course1</td>\n      <td>m31I6cTD</td>\n      <td>79.493475</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>604234</td>\n      <td>course1</td>\n      <td>m31I6cTD</td>\n      <td>96.732014</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>992922</td>\n      <td>course1</td>\n      <td>m31I6cTD</td>\n      <td>78.152273</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>488841</td>\n      <td>course1</td>\n      <td>m31I6cTD</td>\n      <td>91.100404</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>831322</td>\n      <td>course1</td>\n      <td>m31I6cTD</td>\n      <td>80.736409</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>940245</td>\n      <td>course1</td>\n      <td>m31I6cTD</td>\n      <td>77.279305</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>543834</td>\n      <td>course1</td>\n      <td>m31I6cTD</td>\n      <td>76.189222</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>775703</td>\n      <td>course1</td>\n      <td>m31I6cTD</td>\n      <td>94.676780</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>967766</td>\n      <td>course1</td>\n      <td>m31I6cTD</td>\n      <td>92.991006</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>291359</td>\n      <td>course1</td>\n      <td>m31I6cTD</td>\n      <td>92.838528</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>226218</td>\n      <td>course1</td>\n      <td>m31I6cTD</td>\n      <td>93.928139</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>108246</td>\n      <td>course1</td>\n      <td>m31I6cTD</td>\n      <td>77.652948</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>209909</td>\n      <td>course1</td>\n      <td>m31I6cTD</td>\n      <td>74.718753</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>908801</td>\n      <td>course1</td>\n      <td>m31I6cTD</td>\n      <td>83.186801</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>227895</td>\n      <td>course1</td>\n      <td>m31I6cTD</td>\n      <td>75.182662</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>360479</td>\n      <td>course1</td>\n      <td>m31I6cTD</td>\n      <td>94.370470</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>121935</td>\n      <td>course1</td>\n      <td>m31I6cTD</td>\n      <td>82.601041</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>516713</td>\n      <td>course1</td>\n      <td>m31I6cTD</td>\n      <td>96.092630</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>553260</td>\n      <td>course1</td>\n      <td>m31I6cTD</td>\n      <td>74.761820</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>862740</td>\n      <td>course1</td>\n      <td>m31I6cTD</td>\n      <td>85.244504</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>282390</td>\n      <td>course1</td>\n      <td>m31I6cTD</td>\n      <td>90.547718</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>835300</td>\n      <td>course1</td>\n      <td>m31I6cTD</td>\n      <td>93.674514</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>974852</td>\n      <td>course1</td>\n      <td>m31I6cTD</td>\n      <td>77.625464</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>401010</td>\n      <td>course1</td>\n      <td>m31I6cTD</td>\n      <td>97.048561</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>321731</td>\n      <td>course1</td>\n      <td>m31I6cTD</td>\n      <td>96.680884</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>864600</td>\n      <td>course1</td>\n      <td>m31I6cTD</td>\n      <td>69.128782</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7970</th>\n      <td>847249</td>\n      <td>course8</td>\n      <td>Vdo50vyP</td>\n      <td>70.899865</td>\n    </tr>\n    <tr>\n      <th>7971</th>\n      <td>128696</td>\n      <td>course8</td>\n      <td>Vdo50vyP</td>\n      <td>86.485209</td>\n    </tr>\n    <tr>\n      <th>7972</th>\n      <td>300487</td>\n      <td>course8</td>\n      <td>Vdo50vyP</td>\n      <td>88.387140</td>\n    </tr>\n    <tr>\n      <th>7973</th>\n      <td>173400</td>\n      <td>course8</td>\n      <td>Vdo50vyP</td>\n      <td>94.369555</td>\n    </tr>\n    <tr>\n      <th>7974</th>\n      <td>798636</td>\n      <td>course8</td>\n      <td>Vdo50vyP</td>\n      <td>80.136739</td>\n    </tr>\n    <tr>\n      <th>7975</th>\n      <td>201431</td>\n      <td>course8</td>\n      <td>Vdo50vyP</td>\n      <td>82.250987</td>\n    </tr>\n    <tr>\n      <th>7976</th>\n      <td>445198</td>\n      <td>course8</td>\n      <td>Vdo50vyP</td>\n      <td>74.905930</td>\n    </tr>\n    <tr>\n      <th>7977</th>\n      <td>919396</td>\n      <td>course8</td>\n      <td>Vdo50vyP</td>\n      <td>68.487291</td>\n    </tr>\n    <tr>\n      <th>7978</th>\n      <td>906998</td>\n      <td>course8</td>\n      <td>Vdo50vyP</td>\n      <td>93.140250</td>\n    </tr>\n    <tr>\n      <th>7979</th>\n      <td>422930</td>\n      <td>course8</td>\n      <td>Vdo50vyP</td>\n      <td>90.114455</td>\n    </tr>\n    <tr>\n      <th>7980</th>\n      <td>955606</td>\n      <td>course8</td>\n      <td>Vdo50vyP</td>\n      <td>69.336953</td>\n    </tr>\n    <tr>\n      <th>7981</th>\n      <td>979995</td>\n      <td>course8</td>\n      <td>Vdo50vyP</td>\n      <td>95.177022</td>\n    </tr>\n    <tr>\n      <th>7982</th>\n      <td>841637</td>\n      <td>course8</td>\n      <td>Vdo50vyP</td>\n      <td>93.259788</td>\n    </tr>\n    <tr>\n      <th>7983</th>\n      <td>907040</td>\n      <td>course8</td>\n      <td>Vdo50vyP</td>\n      <td>81.916620</td>\n    </tr>\n    <tr>\n      <th>7984</th>\n      <td>691675</td>\n      <td>course8</td>\n      <td>Vdo50vyP</td>\n      <td>89.781922</td>\n    </tr>\n    <tr>\n      <th>7985</th>\n      <td>743527</td>\n      <td>course8</td>\n      <td>Vdo50vyP</td>\n      <td>78.000457</td>\n    </tr>\n    <tr>\n      <th>7986</th>\n      <td>359824</td>\n      <td>course8</td>\n      <td>Vdo50vyP</td>\n      <td>74.922013</td>\n    </tr>\n    <tr>\n      <th>7987</th>\n      <td>536667</td>\n      <td>course8</td>\n      <td>Vdo50vyP</td>\n      <td>73.596751</td>\n    </tr>\n    <tr>\n      <th>7988</th>\n      <td>982063</td>\n      <td>course8</td>\n      <td>Vdo50vyP</td>\n      <td>83.467677</td>\n    </tr>\n    <tr>\n      <th>7989</th>\n      <td>548231</td>\n      <td>course8</td>\n      <td>Vdo50vyP</td>\n      <td>83.240466</td>\n    </tr>\n    <tr>\n      <th>7990</th>\n      <td>577866</td>\n      <td>course8</td>\n      <td>Vdo50vyP</td>\n      <td>85.456099</td>\n    </tr>\n    <tr>\n      <th>7991</th>\n      <td>490319</td>\n      <td>course8</td>\n      <td>Vdo50vyP</td>\n      <td>88.503393</td>\n    </tr>\n    <tr>\n      <th>7992</th>\n      <td>521121</td>\n      <td>course8</td>\n      <td>Vdo50vyP</td>\n      <td>74.170431</td>\n    </tr>\n    <tr>\n      <th>7993</th>\n      <td>155585</td>\n      <td>course8</td>\n      <td>Vdo50vyP</td>\n      <td>93.342235</td>\n    </tr>\n    <tr>\n      <th>7994</th>\n      <td>758749</td>\n      <td>course8</td>\n      <td>Vdo50vyP</td>\n      <td>84.934583</td>\n    </tr>\n    <tr>\n      <th>7995</th>\n      <td>743747</td>\n      <td>course8</td>\n      <td>Vdo50vyP</td>\n      <td>86.245411</td>\n    </tr>\n    <tr>\n      <th>7996</th>\n      <td>719678</td>\n      <td>course8</td>\n      <td>Vdo50vyP</td>\n      <td>82.493726</td>\n    </tr>\n    <tr>\n      <th>7997</th>\n      <td>227750</td>\n      <td>course8</td>\n      <td>Vdo50vyP</td>\n      <td>75.746691</td>\n    </tr>\n    <tr>\n      <th>7998</th>\n      <td>181683</td>\n      <td>course8</td>\n      <td>Vdo50vyP</td>\n      <td>71.281673</td>\n    </tr>\n    <tr>\n      <th>7999</th>\n      <td>270481</td>\n      <td>course8</td>\n      <td>Vdo50vyP</td>\n      <td>70.325044</td>\n    </tr>\n  </tbody>\n</table>\n<p>8000 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 52
    }
   ],
   "source": [
    "sub_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "sub_test.to_csv('/home/wjunneng/Python/ForecastScore/data/test_s1/submission_s1_sample_baseline_1.csv',index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.axes._subplots.AxesSubplot at 0x7f54212f4860>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 54
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fi = []\n",
    "for i in cv_model:\n",
    "    tmp = {\n",
    "        'name' : col,\n",
    "        'score' : i.feature_importances_\n",
    "    }\n",
    "    fi.append(pd.DataFrame(tmp))\n",
    "    \n",
    "fi = pd.concat(fi)\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "fi.groupby(['name'])['score'].agg('mean').sort_values(ascending=False).head(40).plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-e50da876",
   "language": "python",
   "display_name": "PyCharm (ForecastScore)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}